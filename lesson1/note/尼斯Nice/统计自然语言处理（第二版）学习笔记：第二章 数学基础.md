# 第二章 数学基础
## 2.1 概率论基础
### 基本概念
#### 2.1.1 概率
两类问题：
  
决策规则由函数sgn(f(x))给出，通常sgn(0)=1.

**概率**(probability)是从随机试验中的事件到实数域的映射函数，用以表示事件发生的可能性。
P(A)表示事件A的概率，Ω是试验的样本空间，概率函数必须满足三条公理：
1.（非负性）P(A)>=0
2.（规范性）P(Ω)=1
3.（可列可加性）若事件两两互不形容，则
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173529571.png)


#### 2.1.2 最大似然估计
如果{s1，s2，…，sn}是一个试验的样本空间，在相同的情况下重复试验N次，观察到样本sk(1≤k≤n)的次数为nN(sk)，那么，sk在这N次试验中的相对频率为
![在这里插入图片描述](https://img-blog.csdnimg.cn/201908291725170.png)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172537356.png)



#### 2.1.3 条件概率
P(A|B)=P(A∩B)/P(B)，三个基本性质
1.（非负性）
2.（规范性）
3.（可列可加性）如果事件A1,A2,...两两互不形容，则
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172640742.png)
若Ai,Aj条件独立，当且仅当[外链图片转存失败
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172655100.png)
乘法规则![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172712364.png)


#### 2.1.4 贝叶斯法则
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172732816.png)![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172740859.png)

全概率公式

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172753968.png)

**决策理论：**
如果类别只有两类，则
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172808295.png)
l(x)为似然比，P(W2)/P(W1)为似然比阈值
#### 2.1.5 期望和方差

期望值是指随机变量所取值的概率平均。
假设X为一随机变量，其概率分布P(X=xk)=pk,k=1,2,...,若级数![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172834789.png)绝对收敛，则随机变量X的数学期望或概率平均值为
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172906619.png)
方差描述的是随机变量的值偏离其期望值的程度。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172923121.png)


## 2.2 信息论基础
### 2.2.1 熵

**熵**描述一个随机变量的不确定性的数量。



若X为离散型随机变量，取值空间R，其概率分布：p(x)=p(X=x),x∈R，则**X的熵H(X)为**：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172935103.png)
其中，0log0=0，通常将log2p(x)写成logp(x)。

**常见语言的熵：**
        

|语言  |熵  |
| --- | --- |
| 意大利语言 |4.00  |
|西班牙语言  |4.01  |
|英语  |4.03  |
|法语  |3.98  |
|俄语  |4.35  |
|  |  |

**专有名词**：人名、地名、组织机构名，又称为命名实体。

### 2.2.2 联合熵
**联合熵**是描述一对随机变量平均所需要的信息量。

若X,Y是一对离散型随机变量X,Y~p(x,y)，X,Y的联合熵H(X,Y)为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829172951111.png)


### 2.2.3 条件熵

随机变量X已知，随机变量Y的条件熵定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173015622.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)


H(X,Y)=H(X)+H(Y|X)=H(Y)+H(X|Y)（连锁规则），H(X|Y)!=H(Y|X)
一般情况，![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173023572.png)


### 2.2.4 熵率

对于一条长度为n的信息，每一个字符或字的熵为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173042348.png)
变量X1n表示随机变量序列（X1,...Xn），x1n=(x1,...,xn)表示随机变量的具体取值。

假定一种语言是由一系列符号组成的随机过程，L=(Xi)，例如某报纸的一批语料，则可以定义这种语言L的熵作为其随机过程的熵率：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173051816.png)


### 2.2.5 相对熵（KL距离）

衡量相同事件空间里两个概率分布相对差距的测度。

两个概率分布p(x)和q(x)的相对熵定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173107411.png)

约定0log(0/q)=0,plog(p/0)=∞，表示成期望值为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173120290.png)
当两个随机分布相同时，其相对熵为0。当两个随机分布的差别增加时，其相对熵也增加。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173131494.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
互信息实际上衡量一个联合分布与独立性差距多大的测度：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173143169.png)
同样，条件相对熵和相对熵的连锁规则：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173152451.png)



### 2.2.6 交叉熵

交叉熵的概念就是用来衡量估计模型与真实概率分布之间差异情况的。



1.若一个随机变量X~p(x)，q(x)用于近似P(x)的概率分布，则随机变量X和模型q之间的交叉熵定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173204752.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

2.对于语言L=(X)~p(x)与其模型q的交叉熵定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173215115.png)
其中，![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173224393.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

由于真实概率p(x1n)并不知道，因此无法计算这个语言的条件熵。


3.假定语言L是稳态遍历性随机过程，x1n为L的样本，有：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173234534.png)

交叉熵与模型在测试语料中分配给每个单词的平均概率所表达的含义正好相反， 模型的交叉熵越小， 模型的表现越好。



### 2.2.7 困惑度

常用困惑度来代替交叉熵衡量语言模型的好坏。


给定语言L的样本l1n=l1...ln，L的困惑度PPq定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173245714.png)
语言模型设计的任务就是寻找困惑度最小的模型，使其最接近真实的语言。
nlp中，是指语言模型对于测试数据的困惑度。

### 2.2.8 互信息
如果（X,Y）~p(x,y)，X,Y之间的互信息I(X;Y)定义为：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173255646.png)
根据H(X)和H(X|Y)的定义：
![在这里插入图片描述](https://img-blog.csdnimg.cn/2019082917331426.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)
得出![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173337659.png)

互信息I(X; Y)反应的是知道了Y的值以后X的不确定性的减少量，即Y的值透露了多少关于X的信息量。

互信息、条件熵与联合熵之间的关系：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173349740.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

H(X)=H(X)-H(X|X)=I(X;X)，H(X|X)=0，说明两个完全相互依赖的变量之间的互信息并不是一个常量，而是取决于他们的熵。

互信息体现了两变量之间的依赖程度：
I》0,高度相关；I=0,相互独立；I《0，增大了X的不确定性。
平均互信息量是非负的。

条件互信息和互信息的连锁规则：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173403372.png)

## 2.3 支持向量机

### 2.3.1 线性分类

#### 两类问题：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173412138.png)


决策规则由函数sgn(f(x))给出，通常sgn(0)=1.

该分类方法的几何解释是， 方程式〈w·x〉 ＋b＝0定义的超平面将输入空间X分成两半， 一半为负类， 一半为正类， 以最大间隔分开数据的超平面称为最优超平面。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173421207.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1hCX3BsZWFzZQ==,size_16,color_FFFFFF,t_70)

#### 多分类问题：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173430778.png)

几何意义: 给每个类关联一个超平面， 然后，将新点x赋予超平面离其最远的那一类。 输入空间分为m个简单相连的凸区域。


### 2.3.2 线性不可分
对于非线性问题，可以把样本x映射到某个高维特征空间，在高维特征空间中使用线性学习器。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173440762.png)
φ：X->F是从输入空间X到特征空间F的映射。


### 2.3.3 核函数
核是一个函数K， 对所有x, z∈X， 满足![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173452756.png)
φ是从X到（内积）特征空间F的映射。



 决策规则（可用测试点和训练点的内积表示）可以通过对核函数的l次计算得到：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173502209.png)


K(x,z)是核函数的充分必要条件是矩阵![在这里插入图片描述](https://img-blog.csdnimg.cn/20190829173513296.png)
是半正定的（即特征值非负）。










    






